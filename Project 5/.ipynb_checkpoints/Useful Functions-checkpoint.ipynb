{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soc. 5 Spring 2019\n",
    "\n",
    "## Functions\n",
    "\n",
    "**Note:** You are not required to submit this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook will walk you through the usage of many functions that you'll need for Project 5, so it's highly recommended that you go through this notebook first, before attempting the Project 5 notebook.\n",
    "\n",
    "We will pick up where we left off in `Discussion 1`, so if you still feel shaky in using Jupyter notebooks, or are unsure what Python variables are, then be sure to review that notebook first, especially the \"Intro to Python\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've hopefully covered the basics in the discussions, let's go over some functions you'll encounter on the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the functions we need\n",
    "from functions import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcharts:\n",
    "To create a barchart, use the `barchart()` function. This function takes a list of categories first, the frequency of each category second, the x-axis label third, y-axis label fourth, the title of the graph fifth, and, finally, the filename for saving the graph, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "categories = array(\"gruyere\", \"brie\", \"cheddar\", \"provolone\")\n",
    "frequencies = array(10 , 30, 100, 60)\n",
    "\n",
    "barchart(categories, frequencies, \"Cheese Type\", \"Popularity\", \"Cheese Popularities\", \"cheese_chart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms:\n",
    "To create a histogram, use the `histogram()` function. This function takes in an array of numerical values first, the x-axis label, the y-axis label, the title of the graph, and the filename for saving the graph, in that order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a histogram to plot the distribution of the sum of 5 dice rolls. We will first simulate these dice rolls with the function below. Don't worry about the code in the function. All you need to know is that a \"sample\" means rolling the dice 5 times and adding up the results, and here, we're taking 50 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and ignore\n",
    "def simulate_dice_rolls(n=5, num_samples=50, func=np.sum):\n",
    "    results = []\n",
    "    for _ in range(0, num_samples):\n",
    "        results.append(func(np.random.randint(1, 6 + 1, size=n)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "dice_distribution = simulate_dice_rolls(5, 50)\n",
    "histogram(dice_distribution, \n",
    "          \"Result\",\n",
    "          \"Frequencies\",\n",
    "          \"The Distribution of the Sum of 5 Dice Rolls (50 Samples)\", \n",
    "          \"dice_roll_histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The figures that you produce using `histogram()` and `barchart()` are saved in the \"Output\" folder. Make sure you give each graph a unique filename so that they don't overwrite each other!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grades Data\n",
    "\n",
    "For the next couple examples, let's use the following small grades dataset to illustrate some functions that might be helpful as you are doing the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_and_score = Table().with_columns([\n",
    "        'letter', array('a', 'b', 'c','d','f', 'i'),\n",
    "        'count',  array( 9,   10,   7,  5,  4,  1),\n",
    "        'points', array(10,   8,   6,  4,  2,  0),\n",
    "        ])\n",
    "\n",
    "grade_and_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Values:\n",
    "To filter values from a table, use the `filter_values()` function. This function takes in the name of the table first, the column that you're filtering, and an array of values to be removed.\n",
    "\n",
    "Let's say you want to filter values 1 and 9 from the `count` column. `filter_values` will drop all rows where `count` has a value of 1 or 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_values(grade_and_score, 'count', array(1, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Categories:\n",
    "To create a categorical variable from another numerical column, use the `create_categories()` function. This function takes in the name of the table, the column that contains the values you want to \"categorize\", and, finally, the endpoints of each category.\n",
    "\n",
    "**Warning:** Make sure you cover the whole range of values that are in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to create a category for the range a value in the column column falls in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min of the count column\n",
    "np.min(grade_and_score.column(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max of the count column\n",
    "np.max(grade_and_score.column(\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, our first endpoint should be 1, and the last endpoint should be 10, and we can divide the range from 1 to 10 however we choose.\n",
    "\n",
    "Here, we're dividing the range of `count` into 2 groups, 0-5, and 6-10+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the table from above to create a categorical variable for count\n",
    "create_categories(grade_and_score, 'count', array(0, 6, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSS 2014\n",
    "For the next couple examples, we'll use our familiar GSS 2014 data that we've been working with for the previous discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Table.read_table(\"Data/GSS_2014_cleaned.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Tabulation:\n",
    "To create a cross-tabulation of two columns of a table, use the `cross_tab()` function. This function takes in: the name of a table, the column to use for the column values, and column to use for row values, in that order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table shows the relationship between letter grades and point values.\n",
    "x_tb = cross_tab(data, 'SEX', 'NATFARE')\n",
    "x_tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this two way table, we can also see the corresponding table of expected counts under the Null Hypothesis that the two columns aren't related. We do this using the `expected_counts()` function, which takes in a cross_tab table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tb = expected_counts(x_tb)\n",
    "exp_tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Statistic\n",
    "Using the cross tabulated and expected counts tables, we can use `compute_chi_square()` to obtain the Chi-Square Statistic, which takes the cross_tab table first, and then, the expected counts table, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_chi_square(x_tb, exp_tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Tables:\n",
    "To find the count of each column's values, we can \"group\" the table by that value, using the `.group()` function on the table, with the column of interest as the parameter. For example, let's see the count of each response to `NATFARE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.group(\"NATFARE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we specify a function as the second paramter/argument to `.group()`, we can calculate other statistics over the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.group(\"NATFARE\", np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can see that taking the mean of some of these columns, such as the nominal `CASEID` column doesn't make sense. Then, it's preferable to select a subset of the columns, and select the ones that we do care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data.select([\"EDUC\", \"AGE\", \"NATFARE\"])\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we group by `NATFARE`, we only get the columns we need. What the table below is showing is the mean of the `EDUC` and `AGE` values for everyone who responded with the corresponding  `NATFARE` response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset.group(\"NATFARE\", np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use other functions with `.group()`. Let's say we wanted the `median` or `range` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.group(\"NATFARE\", np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.group(\"NATFARE\", np.range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, here are all the array functions we discussed in the first discussion:\n",
    "- _np.mean()_: calculates the mean of an array \n",
    "- _np.median()_: calculates the median of an array\n",
    "- _np.mode()_: calculates the mode of an array \n",
    "- _np.var()_: calculates the variance of an array \n",
    "- _np.std()_: calculates the standard deviation of an array\n",
    "- _np.range()_: calculates the range of an array\n",
    "- _np.sum()_: calculates the sum of all values in an array\n",
    "\n",
    "All of these can be used with the `.group()` function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
